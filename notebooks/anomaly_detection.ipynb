{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import scipy as sp\n",
    "\n",
    "import torch\n",
    "import pygsp\n",
    "import optuna\n",
    "import joblib\n",
    "import gc\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from matplotlib.ticker import ScalarFormatter, StrMethodFormatter, FormatStrFormatter, FuncFormatter\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from optuna.samplers import TPESampler, BruteForceSampler\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn.models import GraphUNet\n",
    "from torch_geometric.nn import GCNConv, Sequential\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx, grid\n",
    "\n",
    "import sensors.utils.fault_detection as fd\n",
    "import sensors.utils.analysis as ana\n",
    "\n",
    "from importlib import reload\n",
    "ana = reload(ana)\n",
    "\n",
    "from pyprojroot import here\n",
    "ROOT_DIR = str(here())\n",
    "data_dir = '/Users/vitorro/Repositories/dario/data/interim/'\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "matplotlib.rcParams.update({'font.family': 'Times New Roman'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONSET DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'df_Gjerdrum_D1L2B'\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "df = pd.read_parquet(data_dir+f\"{dataset}_filtered.parq\")\n",
    "\n",
    "# Getting features\n",
    "df['grad'] = df.groupby('pid').smoothed.transform(np.gradient)\n",
    "# df['grad2'] = df.groupby('pid').grad.transform(np.gradient)\n",
    "df['grad_abs'] = df.grad.abs()\n",
    "\n",
    "print('grads done')\n",
    "\n",
    "df = ana.center_column(df, 'smoothed', 'grad_abs', 'centered')\n",
    "df['grad_idmax'] = df.groupby('pid', as_index=False)['grad_abs'].transform(lambda x: np.argmax(x))\n",
    "\n",
    "print('centering done')\n",
    "\n",
    "\n",
    "# Detecting anomalies (pixels with large gradient)\n",
    "threshold = 0.65\n",
    "\n",
    "# Group by 'pid' and find the row with the maximum 'grad_abs' for each sensor\n",
    "id_list = df.query('grad_abs>@threshold').pid.unique()\n",
    "df_list = df[df.pid.isin(id_list)]\n",
    "print(f'pixels with grad>threshold: {len(id_list)}')\n",
    "\n",
    "df_regions = []\n",
    "for pid in id_list:\n",
    "    df_regions.append(ana.get_df_onset(df.query('pid==@pid'), threshold=threshold, clustering_length=120))\n",
    "\n",
    "df_regions = pd.concat(df_regions).reset_index()\n",
    "\n",
    "display(df_regions.head())\n",
    "display(df_regions.groupby('pid', as_index=False).onset_case.min().onset_case.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions.to_parquet(data_dir+f'{dataset}_onset.parq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'df_Gjerdrum_D1L2B'\n",
    "df_orig = pd.read_parquet(data_dir+f\"{dataset}_filtered.parq\")\n",
    "df_regions = pd.read_parquet(data_dir+f'{dataset}_onset.parq')\n",
    "df_regions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "df_cluster = df_regions.query('onset_case==1 or onset_case==2').copy()\n",
    "df_cluster, y_pred = ana.tskmeans(df_cluster, cluster_by='centered', cluster_to='dtw_clusters', metric='dtw',\n",
    "                                  n_clusters=n_clusters, n_init=5)\n",
    "df_cluster.to_parquet(data_dir+f'{dataset}_cluster.parq')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensors-BoU2skHt-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
